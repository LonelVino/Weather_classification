{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":["## Simple CNN\n","The goal here is to create a baseline pipeline to do snow(daydd/night?) classification, we'll be using a simple CNN network as baseline"],"metadata":{}},{"cell_type":"markdown","source":["### Loading the dataset\n","\n","Load the dataset from the weather type and data type (train \\ test \\ validation)"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["import os\n","import numpy as np\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import cv2\n","%matplotlib inline\n","\n","# Choose which task to work on: fog, night, rain or snow\n","def load_images(weather_type, data_type):\n","    \"\"\"\n","    Load images from the weather_type/data_type folder\n","    :param weather_type: fog or night or rain or snow\n","    :type weather_type: String\n","    :param data_type: train or val or test or train_ref or val_ref or test_ref\n","    :type data_type: String\n","    :return: list of images and list of respective paths\n","    :rtype: Lists\n","    \"\"\"\n","    data = []\n","    data_paths = []\n","    counter = 0\n","    path = '../input/acdc-dataset/dataset ACDC/rgb_anon/' + weather_type + '/' + data_type + '/'\n","\n","    # For each Gopro directory, for each image, store the image and its path in train and train_paths respectively\n","    for directory_name in os.listdir(path):\n","        gopro_path = path + directory_name\n","        for image_name in os.listdir(gopro_path):\n","            image_path = gopro_path + \"/\" + image_name\n","            image = Image.open(image_path)\n","            data.append(image)\n","            data_paths.append(image_path)\n","\n","            # Counter to see progression\n","            counter += 1\n","            if counter%100 == 0:\n","                print(str(counter) + \" \" + data_type + \" images loaded\")\n","    \n","    return data, data_paths"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:44:49.493698Z","iopub.execute_input":"2021-10-07T17:44:49.494134Z","iopub.status.idle":"2021-10-07T17:44:49.504383Z","shell.execute_reply.started":"2021-10-07T17:44:49.494092Z","shell.execute_reply":"2021-10-07T17:44:49.503303Z"},"trusted":true}},{"cell_type":"markdown","source":["Load the dataset of night, respectively set as varaibles: `train_day`, `train_night`, `valid_day`, `valid_night` "],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["train_day, train_day_paths = load_images('night', 'train_ref')\n","train_night, train_night_paths = load_images('night', 'train')\n","valid_day, valid_day_paths = load_images('night', 'val_ref')\n","valid_night, valid_night_paths = load_images('night', 'val')"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:44:49.506109Z","iopub.execute_input":"2021-10-07T17:44:49.506576Z","iopub.status.idle":"2021-10-07T17:44:51.39546Z","shell.execute_reply.started":"2021-10-07T17:44:49.506537Z","shell.execute_reply":"2021-10-07T17:44:51.393542Z"},"trusted":true}},{"cell_type":"markdown","source":["### Build CNN Model"],"metadata":{}},{"cell_type":"markdown","source":["Load functions:\n","- `accuracy()`: the function to evaluate the accuracy\n","- `train_epoch()`: perform one Training epoch\n","- `valid_epoch()`: perform one Validation epoch\n","- `show_batch()`: plot images from batch"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["import utils\n","import train_val_scripts"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["Import Troch libraries"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# importing required libraries\n","\n","import torch\n","import torch.nn as nn\n","from torchvision import transforms\n","from tqdm import tqdm"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:47:07.544756Z","iopub.execute_input":"2021-10-07T17:47:07.545734Z","iopub.status.idle":"2021-10-07T17:47:07.551537Z","shell.execute_reply.started":"2021-10-07T17:47:07.545698Z","shell.execute_reply":"2021-10-07T17:47:07.550801Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["all_files = train_day_paths + train_night_paths"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:47:07.55262Z","iopub.execute_input":"2021-10-07T17:47:07.553154Z","iopub.status.idle":"2021-10-07T17:47:07.559924Z","shell.execute_reply.started":"2021-10-07T17:47:07.553115Z","shell.execute_reply":"2021-10-07T17:47:07.559316Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["# arrays to store avg. mean and std of Value channel from each image\n","means = []\n","stds = []\n","\n","# simple loop to iterate over every image and append mean and std of V channel from HSV image.\n","for curr_file in tqdm(all_files):\n","  img = cv2.imread(str(curr_file))\n","  img = cv2.resize(img, (500,500))\n","  img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n","  img = img/255.0\n","  means.append(np.mean(img[:, :, 2]))\n","  stds.append(np.std(img[:, :, 2]))"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:47:07.561226Z","iopub.execute_input":"2021-10-07T17:47:07.561478Z","iopub.status.idle":"2021-10-07T17:47:50.935047Z","shell.execute_reply.started":"2021-10-07T17:47:07.561446Z","shell.execute_reply":"2021-10-07T17:47:50.934315Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["# avg mean and std for normalization\n","avg_mean = sum(means)/len(means)\n","avg_std = sum(stds)/len(stds)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:47:50.939409Z","iopub.execute_input":"2021-10-07T17:47:50.939839Z","iopub.status.idle":"2021-10-07T17:47:50.944851Z","shell.execute_reply.started":"2021-10-07T17:47:50.939801Z","shell.execute_reply":"2021-10-07T17:47:50.944193Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["avg_mean, avg_std"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:47:50.946295Z","iopub.execute_input":"2021-10-07T17:47:50.946837Z","iopub.status.idle":"2021-10-07T17:47:50.956035Z","shell.execute_reply.started":"2021-10-07T17:47:50.946797Z","shell.execute_reply":"2021-10-07T17:47:50.955256Z"},"trusted":true}},{"cell_type":"markdown","source":["### Creating PyTorch Dataset and DataLoader"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# PyTorch custom dataset class to load image and convert to HSV\n","class HSV_Dataset(nn.Module):\n","  def __init__(self, day_files, night_files):\n","    super().__init__()\n","    self.files = day_files + night_files\n","    \n","    # augmentations to convert image to pytorch tensor and normalize using mean and std\n","    self.augs = transforms.Compose([\n","                transforms.ToTensor(),\n","                transforms.Normalize([0.32225], [0.21580])\n","    ])\n","\n","  def __getitem__(self, idx):\n","    # reading image\n","    img = cv2.imread(str(self.files[idx]))\n","    # resizing to standard size\n","    img = cv2.resize(img, (500,500))\n","    # converting to HSV colorspace\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n","    # splitting channels of HSV image\n","    h,s,v = cv2.split(img)\n","    # normalizing v channel of HSV image\n","    v = self.augs(v)\n","    \n","    # extracting label from pathlib path\n","    cls = str(self.files[idx]).split('/')[-3]\n","\n","    # label = 1 if day else 0\n","    if cls == 'day':\n","      label = 1\n","    else: \n","      label = 0\n","      \n","    return v, label\n","\n","  def __len__(self):\n","    return len(self.files)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:47:50.95763Z","iopub.execute_input":"2021-10-07T17:47:50.958014Z","iopub.status.idle":"2021-10-07T17:47:50.968777Z","shell.execute_reply.started":"2021-10-07T17:47:50.957968Z","shell.execute_reply":"2021-10-07T17:47:50.967894Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["# training and validation datasets\n","train_ds = HSV_Dataset(train_day_paths, train_night_paths)\n","valid_ds = HSV_Dataset(valid_day_paths, valid_night_paths)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:47:50.970236Z","iopub.execute_input":"2021-10-07T17:47:50.970493Z","iopub.status.idle":"2021-10-07T17:47:50.978356Z","shell.execute_reply.started":"2021-10-07T17:47:50.970461Z","shell.execute_reply":"2021-10-07T17:47:50.977493Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["# training and validation dataloaders\n","train_dl = torch.utils.data.DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=2, pin_memory=True)\n","valid_dl = torch.utils.data.DataLoader(valid_ds, batch_size=32, shuffle=False, num_workers=2, pin_memory=True)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:47:50.979836Z","iopub.execute_input":"2021-10-07T17:47:50.980144Z","iopub.status.idle":"2021-10-07T17:47:50.987872Z","shell.execute_reply.started":"2021-10-07T17:47:50.980102Z","shell.execute_reply":"2021-10-07T17:47:50.986946Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["classes = ['night', 'day']\n","x,y = next(iter(valid_dl))"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:47:50.989573Z","iopub.execute_input":"2021-10-07T17:47:50.989903Z","iopub.status.idle":"2021-10-07T17:47:55.3195Z","shell.execute_reply.started":"2021-10-07T17:47:50.989872Z","shell.execute_reply":"2021-10-07T17:47:55.318609Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["# visualization of sample images\n","show_batch(x, [classes[i] for i in y], nimgs=4, mean=torch.Tensor([0.32225]), std=torch.Tensor([0.21580]), denorm=False)"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"markdown","source":["### Build a CNN Model"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# Simple function that returns a Conv-BatchNorm-ReLU layer\n","def conv_bn_relu(ni, nf, stride=2, bn=True, act=True):\n","  layers = [nn.Conv2d(ni, nf, kernel_size=3, stride=2, padding=1, bias=not bn)] # no need of bias if using batchnorm\n","  if bn:\n","    layers.append(nn.BatchNorm2d(nf))\n","  if act:\n","    layers.append(nn.ReLU(inplace=True))\n","  return nn.Sequential(*layers)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:47:56.087502Z","iopub.execute_input":"2021-10-07T17:47:56.088313Z","iopub.status.idle":"2021-10-07T17:47:56.100219Z","shell.execute_reply.started":"2021-10-07T17:47:56.088271Z","shell.execute_reply":"2021-10-07T17:47:56.099602Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["# Simple layer to flatten output of previous layer\n","class Flatten(nn.Module):\n","  def forward(self, x):\n","    return x.squeeze()"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:47:56.101443Z","iopub.execute_input":"2021-10-07T17:47:56.102645Z","iopub.status.idle":"2021-10-07T17:47:56.114097Z","shell.execute_reply.started":"2021-10-07T17:47:56.102593Z","shell.execute_reply":"2021-10-07T17:47:56.11307Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["# Simple 5-layer FCN-CNN model that takes as input a V channel of HSV image.\n","simple_model = nn.Sequential(\n","    conv_bn_relu(1, 8),\n","    conv_bn_relu(8, 16),\n","    conv_bn_relu(16, 32),\n","    conv_bn_relu(32, 8),\n","    conv_bn_relu(8, 2, bn=False, act=False), # no batchnorm and relu for last layer\n","    nn.AdaptiveAvgPool2d(1), # taking mean across spatial dimensions, these are logits\n","    Flatten()\n",")"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:47:56.115616Z","iopub.execute_input":"2021-10-07T17:47:56.116163Z","iopub.status.idle":"2021-10-07T17:47:56.143527Z","shell.execute_reply.started":"2021-10-07T17:47:56.116121Z","shell.execute_reply":"2021-10-07T17:47:56.142877Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["simple_model"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:47:56.144759Z","iopub.execute_input":"2021-10-07T17:47:56.145028Z","iopub.status.idle":"2021-10-07T17:47:56.151346Z","shell.execute_reply.started":"2021-10-07T17:47:56.144981Z","shell.execute_reply":"2021-10-07T17:47:56.150475Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["simple_model = simple_model.to(device='cuda:0')"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:47:56.153099Z","iopub.execute_input":"2021-10-07T17:47:56.15342Z","iopub.status.idle":"2021-10-07T17:47:56.170019Z","shell.execute_reply.started":"2021-10-07T17:47:56.153373Z","shell.execute_reply":"2021-10-07T17:47:56.169257Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["# Using Softmax CrossEntropy Loss\n","criterion = nn.CrossEntropyLoss()\n","\n","# Adam optimizer with lr=1e-4\n","opt = torch.optim.Adam(simple_model.parameters(), lr=1e-4) \n","\n","# Cosine Annealing Learning Rate Scheduler\n","scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, len(train_dl)*15, eta_min=1e-6) "],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:47:56.17131Z","iopub.execute_input":"2021-10-07T17:47:56.171583Z","iopub.status.idle":"2021-10-07T17:47:56.177814Z","shell.execute_reply.started":"2021-10-07T17:47:56.171549Z","shell.execute_reply":"2021-10-07T17:47:56.176776Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["max_acc = 0.0 # Track maximum validation accuracy achieved\n","\n","for epoch in range(15):\n","  best = False # Flag to detect best model\n","\n","  # Training phase\n","  train_loss, train_acc = train_epoch(simple_model, train_dl, criterion, opt, scheduler)\n","\n","  # Validation phase\n","  valid_loss, valid_acc = valid_epoch(simple_model, valid_dl, criterion)\n","\n","\n","  if valid_acc > max_acc: # Saving best model\n","    max_acc = valid_acc\n","    torch.save(simple_model.state_dict(), 'simple_best_model.pth')\n","    best = True\n","\n","  print('-'*25 + f'Epoch {epoch+1}' + '-'*25)\n","  print(f'Train Loss:{train_loss} Train Accuracy:{train_acc}')\n","  print(f'Valid Loss:{valid_loss} Valid Accuracy:{valid_acc}')\n","  if best:\n","    print(f'Found better model!')\n","  print('-'*58)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:47:56.179129Z","iopub.execute_input":"2021-10-07T17:47:56.179468Z"},"trusted":true}},{"cell_type":"markdown","source":["## "],"metadata":{}}]}